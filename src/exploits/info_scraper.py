import os
import requests
from bs4 import BeautifulSoup
from urllib.request import urlretrieve
from Webcrawler import WebCrawler

colors = {
    'BLUE': '\33[1;94m',
    'RED': '\033[1;91m',
    'WHITE': '\33[1;97m',
    'YELLOW': '\33[1;93m',
    'MAGENTA': '\033[1;35m',
    'GREEN': '\033[1;32m',
    'END': '\033[0m',
}


class ScraperInfo(WebCrawler):

    global colors

    def __init__(self, base_url):
        super().__init__(base_url)

    def source_code(self, name="index"):
        directory = str(os.getcwd())
        request = requests.get(self.base_url)

        # bs4 object
        bs_obj = BeautifulSoup(request.text, "lxml")
        html_code = bs_obj.prettify()

        file = "{}.html".format(name)

        with open(os.path.join(directory, file), "w") as f:
            f.write(html_code)

        print(colors["RED"], "Your file has been saved in {} as {}".format(directory, file), colors["END"])

    def http_headers(self):
        request = requests.get(self.base_url)
        # HTTP headers
        TAB = "\t" * 5
        print(colors["YELLOW"], TAB, request.headers, colors["END"])

    def site_images(self):
        links = set()
        request = requests.get(self.base_url)
        bs_obj = BeautifulSoup(request.text, "lxml")
        for link in bs_obj.find_all('img', src=True):
            download_url = link['src']
            print("[+] Storing => {}".format(download_url))
            links.add(download_url)

        index = 0
        try:
            for link in links:
                urlretrieve(link, "{}{}.jpg".format(self.base_url.replace("https://", ""), index))
                index += 1
        except Exception as e:
            print(colors["RED"], "Error => ", e, colors["END"])

    def comment_harvester(self):
        """Harvests comments on pages for later analysis"""
        url = requests.get(self.base_url)
        # look for any comment
        comments = re.findall("<!--(.*)-->", url.text)
        print("Comments found on {}".format(self.base_url))
        for comment in comments:
            # I just like being sure
            if comment is not None:
                print(colors["BLUE"], comment, colors["END"])

        bs_obj = BeautifulSoup(url.text, "lxml")
        urls = []
        for link in bs_obj.find_all('a', href=True):
            urls.append(link['href'])

        for link in urls:
            url = requests.get(link)
            comments = re.findall("<!--(.*)-->", url.text)
            for comment in comments:
                print(colors["YELLOW"], comment, colors["END"])
